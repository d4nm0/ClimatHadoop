{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b707ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install folium\n",
    "!pip3 install dask\n",
    "!pip3 install \"dask[distributed]\" --upgrade\n",
    "!pip3 install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import requests\n",
    "import os\n",
    "import dask\n",
    "from time import sleep\n",
    "from dask import delayed\n",
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec20022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station = pd.read_csv(\"./isd-history.csv\")\n",
    "df_station\n",
    "open_station = df_station[df_station[\"END\"] == 20220502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"data/2022/72011354829.csv\")\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "'STATION':         int,\n",
    "'DATE':           object,\n",
    "'SOURCE':         object,\n",
    "'LATITUDE':      float,\n",
    "'LONGITUDE':     float,\n",
    "'ELEVATION':     float,\n",
    "'NAME':           object,\n",
    "'REPORT_TYPE':    object,\n",
    "'CALL_SIGN':      object,\n",
    "'QUALITY_CONTROL':object,\n",
    "'WND':            object,\n",
    "'CIG':            object,\n",
    "'VIS':            object,\n",
    "'TMP':            object,\n",
    "'DEW':            object,\n",
    "'SLP':            object,\n",
    "'AA1':            object,\n",
    "'AT1':            object,\n",
    "'AT2':            object,\n",
    "'AT3':            object,\n",
    "'AT4':            object,\n",
    "'AT5':            object,\n",
    "'AU1':            object,\n",
    "'AW1':            object,\n",
    "'OC1':            object,\n",
    "'REM':            object,\n",
    "'EQD':            object\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ebd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc260e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./data\"):\n",
    "    os.mkdir(\"./data\")\n",
    "\n",
    "for year in range(2022, 2023):\n",
    "    year = str(year)\n",
    "    path = \"./data/\" + year\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    for key, station_row in open_station.iterrows():\n",
    "        wban = str(station_row.WBAN);\n",
    "\n",
    "        while (len(wban) < 5):\n",
    "            wban = '0' + wban\n",
    "\n",
    "        station  = str(station_row.USAF) + wban\n",
    "\n",
    "        if not os.path.exists(path + \"/\" + station + \".csv\"):\n",
    "            url = 'https://www.ncei.noaa.gov/data/global-hourly/access/' + year + '/' + station + '.csv'\n",
    "\n",
    "            if (requests.get(url).status_code == 200):\n",
    "                #df = pd.read_csv(url)\n",
    "                ddf = dd.read_csv(url, dtype='object')\n",
    "                ddf.to_csv(path + \"/\" + station + \".csv\", index=True, single_file = True)\n",
    "                #df = pd.read_csv(url).to_csv(path + \"/\" + station + \".csv\", index=True)\n",
    "                #sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for year in range(2022, 2023):\n",
    "    year = str(year)\n",
    "    path = \"./data/\" + year\n",
    "\n",
    "    for key, station_row in open_station.iterrows():\n",
    "        wban = str(station_row.WBAN);\n",
    "\n",
    "        while (len(wban) < 5):\n",
    "            wban = '0' + wban\n",
    "\n",
    "        station  = str(station_row.USAF) + wban\n",
    "\n",
    "        if os.path.exists(path + \"/\" + station + \".csv\"):\n",
    "            #df = pd.read_csv(path + \"/\" + station + \".csv\")\n",
    "            #print(df.dtypes)\n",
    "            df = dd.read_csv(path + \"/\" + station + \".csv\", dtype=dtypes)\n",
    "            \n",
    "            \n",
    "            #df = dd.read_csv(path + \"/\" + station + \".csv\")\n",
    "            #df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf4375",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0af2b66b",
   "metadata": {},
   "source": [
    "# Clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89888ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_frame['TMP_control'] = big_frame['TMP'].str.split(pat=',', expand=True)[1]\n",
    "big_frame['TMP_test'] = big_frame['TMP'].str.split(pat=',', expand=True)[0]\n",
    "big_frame['TMP_sign'] = big_frame['TMP'].astype(str).str[0]\n",
    "big_frame['TMP_final'] = (big_frame['TMP_test'].astype(str).str[1:4] + \".\" + big_frame['TMP_test'].astype(str).str[4:]).astype(float)\n",
    "big_frame['DATE'] = pd.to_datetime(big_frame['DATE'], format=\"%Y-%m-%dT%H:%M:%S\")\n",
    "big_frame = big_frame[big_frame['TMP_control'] == \"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e443ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_frame['TMP_sign'].replace({\"+\": 1, \"-\": -1}, inplace=True)\n",
    "big_frame['TMP_final'] = big_frame['TMP_sign'] * big_frame['TMP_final']\n",
    "big_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c278ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_frame = big_frame[[\"NAME\", \"TMP_final\", \"LATITUDE\", \"LONGITUDE\", \"DATE\"]]\n",
    "cleaned_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4604e1",
   "metadata": {},
   "source": [
    "# Statistiques globales de tempÃ©rature (moy, min, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = cleaned_frame.groupby(by=\"NAME\").agg({'TMP_final': ['mean', 'min', 'max'], \"LATITUDE\": \"first\", \"LONGITUDE\": \"first\"})\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for year in range(2022, 2023):\n",
    "#    year = str(year)\n",
    "#    path = \"./data/\" + year\n",
    "\n",
    "#    if not os.path.exists(path):\n",
    "#        os.mkdir(path)\n",
    "\n",
    "#    for key, station_row in open_station.iterrows():\n",
    "#        wban = str(station_row.WBAN);\n",
    "\n",
    "#        while (len(wban) < 5):\n",
    "#            wban = '0' + wban\n",
    "\n",
    "#        station  = str(station_row.USAF) + wban\n",
    "\n",
    "#        if not os.path.exists(path + \"/\" + station + \".csv\"):\n",
    "#            url = 'https://www.ncei.noaa.gov/data/global-hourly/access/' + year + '/' + station + '.csv'\n",
    "\n",
    "#            if (requests.get(url).status_code == 200):\n",
    "#                pd.read_csv(url).to_csv(path + \"/\" + station + \".csv\")\n",
    "\n",
    "#            spark.sparkContext.addFile('https://www.ncei.noaa.gov/data/global-hourly/access/' + year + '/' + station + '.csv')\n",
    "\n",
    "#            if (SparkFiles.get(station + \".csv\")):\n",
    "#                df = spark.read.csv(\"file://\"+SparkFiles.get(station + \".csv\"), header=True)\n",
    "\n",
    "#                print(\"hdfs://namenode:9000/noaa/\" + year + \"/\" + station + \".csv\")\n",
    "#                df.write.format(\"csv\").save(\"hdfs://namenode:9000/noaa/\" + year + \"/\" + station + \".csv\")\n",
    "\n",
    "#for year in range(2022, 2023):\n",
    "\n",
    "#    for key, station_row in open_station.iterrows():\n",
    "#        wban = str(station_row.WBAN);\n",
    "\n",
    "#        while (len(wban) < 5):\n",
    "#            wban = '0' + wban\n",
    "\n",
    "#        station  = str(station_row.USAF) + wban\n",
    "        \n",
    "#        df = spark.read.csv(\"hdfs://namenode:9000/noaa/\" + str(year) + \"/\" + station + \".csv\", header=True)\n",
    "#df = spark.read.csv(\"hdfs://namenode:9000/noaa/2022/72026853882.csv\", header=True)\n",
    "#df.take(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
